{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOj1i80K8dM8SESyrJsmTs/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jvitordeoliveira96/MATH7924/blob/restore/3_KL_Divergence_and_DCI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data-consistent inversion (DCI)\n",
        "\n",
        "\n",
        "$$\n",
        "  \\large \\pi^{update}_\\Lambda(\\lambda) = \\pi_\\Lambda^{initial}(\\lambda) \\frac{\\pi_{\\mathcal{D}}^{obs}(Q(\\lambda))}{\\pi_{\\mathcal{D}}^{predict}(Q(\\lambda))} =  \\pi_\\Lambda^{initial}(\\lambda) r(Q(\\Lambda))\n",
        "$$\n",
        "\n",
        "where\n",
        "\n",
        "* $\\lambda\\in\\Lambda$ $\\to$ model inputs referred to as model parameters.\n",
        "\n",
        "\n",
        " * $Q(\\lambda)$ $\\to$ measurable model outputs referred to as quantities of interest (QoI).\n",
        "\n",
        "\n",
        " * $\\mathcal{D} = Q(\\Lambda)$ $\\to$ set of observable data that can be predicted by the model.\n",
        " <br>\n",
        " * $\\pi_\\mathcal{D}^{obs}$ $\\to$ observed data density\n",
        " *  $\\pi_\\Lambda^{initial}$  $\\to$ initial density of $\\Lambda$\n",
        " * $\\pi_{\\mathcal{D}}^{predict}$ $\\to$ push-forward of the initial density\n",
        " *   $\\pi^{update}_\\Lambda$  $\\to$ updated density of $\\lambda$\n",
        " *  $r$  $\\to$ ratio that represents the mismatch between observed and predicted."
      ],
      "metadata": {
        "id": "y2wcNN_4nNV5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The textbook contains the following paragraph regarding using KL divergence to compare **original** and **updated** distributions:\n",
        "\n",
        "*Taking this as the definition of the value of the integrand when $p = 0$ will make it continuous there. Notice that we do have a problem however if $q = 0$ in some place that $p\\neq 0$. Our information gain requires that our original distribution of beliefs $q$ has some support everywhere the updated distribution does. Intuitively it would require an infinite amount of information for us to update our beliefs in some outcome to change from being exactly $0$ to some positive value.*\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zvpO8gW9tRrr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This relates to the Predictability Assumption:\n",
        "\n",
        " $\\exists$ $C>0$ such that $\\pi_{\\mathcal{D}}^{obs}(q) \\leq C\\pi_{\\mathcal{D}}^{predict}(q)$ for a.e. $q\\in\\mathcal{D}$.\n",
        "\n",
        "The Predictability Assumption enforces that everywhere the observed density $\\pi_{\\mathcal{D}}^{obs}(q)>0$, the push-forward of the initial density has also $\\pi_{\\mathcal{D}}^{predict}(q) > 0$. In other words, the support of push-forward of the initial has to cover the support of the observed data density. If that is not the case, it is not possible to obtain an updated density $\\pi^{update}_\\Lambda$ that is consistent with the observed data."
      ],
      "metadata": {
        "id": "w4ehBJqUvwTJ"
      }
    }
  ]
}