{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "## 1. Definition of KL Divergence\n",
        "\n",
        "For two discrete probability distributions $P = (p_1, \\dots, p_n)$ and $Q = (q_1, \\dots, q_n)$ with $p_i, q_i \\ge 0$ and $\\sum_i p_i = \\sum_i q_i = 1$, the **Kullback–Leibler (KL) divergence** is defined as:\n",
        "\n",
        "$$\n",
        "D_{\\mathrm{KL}}(P\\|Q) = \\sum_{i=1}^n p_i \\ln\\frac{p_i}{q_i},\n",
        "$$\n",
        "\n",
        "requiring $q_i>0$ whenever $p_i>0$.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. From Five properties to Four Properties\n",
        "\n",
        "The following **five properties** uniquely characterize the KL divergence (up to positive scale):\n",
        "\n",
        "1. **Continuity**\n",
        "2. **Non‑negativity**\n",
        "3. **Permutation‑invariance**\n",
        "4. **Monotonic for uniform distributions**\n",
        "5. **Chain‑rule** (grouping)\n",
        "\n",
        "One can equivalently assume the (weaker) **four properties** below:\n",
        "\n",
        "* **(i) Measurability in the second argument**\n",
        "* **(ii) Permutation-invariance**\n",
        "* **(iii) Vanishing**:  $D(P\\|Q)=0$ if and only if $Q = P$.\n",
        "* **(iv) Chain‑rule (grouping)**\n",
        "\n",
        "\n",
        "\n",
        "## 3. Verification of 4 Properties for $D_{\\mathrm{KL}}$\n",
        "\n",
        "Let\n",
        "\n",
        "$$\n",
        "D_{\\mathrm{KL}}(P\\|Q)=\\sum_{i=1}^n p_i \\ln\\frac{p_i}{q_i}.\n",
        "$$\n",
        "\n",
        "1. **Measurability in the second argument**\n",
        "\n",
        "   * For fixed $P$, if $p_i>0$, each term $q_i\\mapsto -p_i\\ln q_i$ is continuous on $\\{q_i>0\\}$, hence measurable. Now, if $p_i = 0$,\n",
        "   $$\\begin{align*} \\lim_{p \\to 0} p \\log\\left(\\frac{p}{q}\\right)&= \\lim_{p \\to 0} p \\log p - \\lim_{p \\to 0} p \\log q \\\\ &= \\lim_{p \\to 0} p \\log p - 0 \\cdot \\log q \\\\ &= \\lim_{p \\to 0} p \\log p \\\\ &= \\lim_{p \\to 0} \\frac{p}{1 / \\log p} \\\\ &= \\lim_{p \\to 0} \\frac{1}{1 / (1/p)} \\quad \\text{(by L'Hôpital's Rule)} \\\\ &= \\lim_{p \\to 0} p = 0.\\end{align*}$$\n",
        "   The function value is then defined to be the result of this limit.\n",
        "\n",
        "\n",
        "   Thus $D_{\\mathrm{KL}}(P\\|Q)$ is measurable in $Q$.\n",
        "\n",
        "2. **Permutation invariant**\n",
        "\n",
        "   * Permuting indices $i\\to\\sigma(i)$ gives the same sum:\n",
        "   $$\\sum_{i=1}^n p_{i} \\log \\frac{p_{i}}{q_{i}} =  \\sum_{i=1}^n p_{\\sigma(i)} \\log \\frac{p_{\\sigma(i)}}{q_{\\sigma(i)}}$$\n",
        "\n",
        "   So $D_{\\mathrm{KL}}$ is invariant under permutation.\n",
        "\n",
        "3. **Vanishing on the diagonal**\n",
        "\n",
        "   * If $P=Q$, then each $\\ln(p_i/q_i)=0$, so $D_{\\mathrm{KL}}(P\\|Q)=0$.\n",
        "   \n",
        "   * If $D_{\\mathrm{KL}}(P\\|Q)=0$, letting $g(t) = t \\log t$,\n",
        "\n",
        "  \n",
        "\n",
        "$$\n",
        "D_{\\mathrm{KL}}(P\\Vert Q)\n",
        "\\;=\\;\\sum_{i=1}^n p_i\\,\\log\\frac{p_i}{q_i} = \\;\\sum_{i=1}^n q_i \\frac{p_i}{q_i}\\,\\log\\frac{p_i}{q_i} = \\sum_{i=1}^n q_i g\\left(\\frac{p_i}{q_i}\\right)\n",
        "$$\n",
        "\n",
        "By Jensen’s inequality,\n",
        "$$\n",
        "\\sum_i q_i\\,g\\!\\bigl(\\tfrac{p_i}{q_i}\\bigr)\n",
        "\\;\\ge\\;\n",
        "g\\!\\Bigl(\\sum_i q_i\\tfrac{p_i}{q_i}\\Bigr)\n",
        "\\;=\\;\n",
        "g\\bigl(1\\bigr)\n",
        "\\;=\\;0,\n",
        "$$\n",
        "\n",
        "and strict convexity forces equality only when\n",
        "$\\tfrac{p_i}{q_i}$ is constant over all $i\\in \\{1,...,n\\}$ with $q_i>0$.  But since both $P$ and $Q$ are probability distributions,\n",
        "$\\sum_{i} p_i=\\sum_i q_i=1$, that constant must be $1$.  Hence\n",
        "\n",
        "$$\n",
        "p_i=q_i\n",
        "\\quad\n",
        "\\forall\\,i \\in \\{1,...,n\\}.\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "4. **Chain‑rule (grouping)**\n",
        "\n",
        "$$D_{\\mathrm{KL}}(P(x,y) \\| Q(x,y)) = D_{\\mathrm{KL}}(P(x) \\| Q(x)) + \\mathbb{E}_{P(x)}[D_{\\mathrm{KL}}(P(y|x) \\| Q(y|x))]$$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### General Chain Rule with Conditional Expectation\n",
        "\n",
        "The general chain rule for KL divergence states:\n",
        "$$D_{\\mathrm{KL}}(P(x,y) \\| Q(x,y)) = D_{\\mathrm{KL}}(P(x) \\| Q(x)) + \\mathbb{E}_{P(x)}[D_{\\mathrm{KL}}(P(y|x) \\| Q(y|x))]$$\n",
        "\n",
        "## Proof of Chain Rule\n",
        "\n",
        " Assuming $Q(x,y) = 0 \\implies P(x,y) = 0$:\n",
        "\n",
        "\n",
        "\n",
        "**Proof:**  \n",
        "1. **Expand joint KL divergence:**  \n",
        "   $$\n",
        "   D_{\\text{KL}}(P \\parallel Q) = \\sum_{x,y} P(x,y) \\log \\left( \\frac{P(x,y)}{Q(x,y)} \\right)\n",
        "   $$\n",
        "\n",
        "2. **Factorize distributions:**  \n",
        "   Substitute $P(x,y) = P(x) \\cdot P(y|x)$ and $Q(x,y) = Q(x) \\cdot Q(y|x)$:  \n",
        "   $$\n",
        "   D_{\\text{KL}}(P \\parallel Q) = \\sum_{x,y} P(x) P(y|x) \\log \\left( \\frac{P(x) P(y|x)}{Q(x) Q(y|x)} \\right)\n",
        "   $$\n",
        "\n",
        "3. **Split the logarithm:**  \n",
        "   $$\n",
        "   \\log \\left( \\frac{P(x) P(y|x)}{Q(x) Q(y|x)} \\right) = \\log \\left( \\frac{P(x)}{Q(x)} \\right) + \\log \\left( \\frac{P(y|x)}{Q(y|x)} \\right)\n",
        "   $$  \n",
        "   Thus:  \n",
        "   $$\n",
        "   D_{\\text{KL}}(P \\parallel Q) = \\underbrace{\\sum_{x,y} P(x) P(y|x) \\log \\left( \\frac{P(x)}{Q(x)} \\right)}_{\\text{Term A}} + \\underbrace{\\sum_{x,y} P(x) P(y|x) \\log \\left( \\frac{P(y|x)}{Q(y|x)} \\right)}_{\\text{Term B}}\n",
        "   $$\n",
        "\n",
        "4. **Simplify Term A:**  \n",
        "   Since $\\log \\left( \\frac{P(x)}{Q(x)} \\right)$ is independent of $y$:  \n",
        "   $$\n",
        "   \\text{Term A} = \\sum_{x} \\log \\left( \\frac{P(x)}{Q(x)} \\right) P(x) \\underbrace{\\sum_{y} P(y|x)}_{=1} = \\sum_{x} P(x) \\log \\left( \\frac{P(x)}{Q(x)} \\right) = D_{\\text{KL}}(P(x) \\parallel Q(x))\n",
        "   $$\n",
        "\n",
        "5. **Simplify Term B:**  \n",
        "   $$\n",
        "   \\text{Term B} = \\sum_{x} P(x) \\underbrace{\\sum_{y} P(y|x) \\log \\left( \\frac{P(y|x)}{Q(y|x)} \\right)}_{D_{\\text{KL}}(P(y|x) \\parallel Q(y|x))} = \\sum_{x} P(x) \\cdot D_{\\text{KL}}(P(y|x) \\parallel Q(y|x))\n",
        "   $$  \n",
        "   \n",
        "\n",
        "6. **Combine results:**  \n",
        "   $$\n",
        "   {D_{\\text{KL}}(P \\parallel Q) = D_{\\text{KL}}(P(x) \\parallel Q(x)) + \\sum_{x} P(x) \\cdot D_{\\text{KL}}(P(y|x) \\parallel Q(y|x))}\n",
        "   $$\n",
        "\n",
        "   $$ \\downarrow$$\n",
        "   $$D_{\\mathrm{KL}}(P(x,y) \\| Q(x,y)) = D_{\\mathrm{KL}}(P(x) \\| Q(x)) + \\mathbb{E}_{P(x)}[D_{\\mathrm{KL}}(P(y|x) \\| Q(y|x))].$$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Uniqueness of KL divergence\n",
        "\n",
        "*The following proof is adapted from \"A short characterization of relative entropy\" (available on https://arxiv.org/pdf/1712.04903).*\n",
        "\n",
        "Let, for each integer $n\\ge1$,\n",
        "\n",
        "$$\n",
        "\\Delta_n = \\bigl\\{\\;\\mathbf{p}=(p_1,\\dots,p_n)\\in\\mathbb{R}^n : p_i\\ge0,\\ \\sum_{i=1}^n p_i = 1\\;\\bigr\\},\n",
        "$$\n",
        "\n",
        "$$\n",
        "A_n = \\bigl\\{\\,(\\mathbf{p},\\mathbf{r})\\in\\Delta_n\\times\\Delta_n : p_i=0\\implies r_i=0\\text{ for all }i\\,\\bigr\\}.\n",
        "$$\n",
        "\n",
        "Suppose we have a family of functions\n",
        "\n",
        "$$\n",
        "I_n : A_n \\;\\longrightarrow\\;\\mathbb{R},\n",
        "$$\n",
        "\n",
        "satisfying:\n",
        "\n",
        "1. **Measurability (in the second argument).**\n",
        "   For each fixed $\\mathbf{p}$, the map\n",
        "   $\\mathbf{r}\\mapsto I_n(\\mathbf{p},\\mathbf{r})$ is Lebesgue‑measurable on its domain.\n",
        "\n",
        "2. **Permutation invariance.**\n",
        "   For any permutation $\\sigma\\in S_n$,\n",
        "\n",
        "   $$\n",
        "     I_n(\\mathbf{p},\\mathbf{r})\n",
        "     =\n",
        "     I_n(\\mathbf{p}_\\sigma,\\mathbf{r}_\\sigma),\n",
        "   $$\n",
        "\n",
        "   where $\\mathbf{p}_\\sigma=(p_{\\sigma(1)},\\dots,p_{\\sigma(n)})$, $\\mathbf{r}_\\sigma=(r_{\\sigma(1)},\\dots,r_{\\sigma(n)})$.\n",
        "\n",
        "3. **Vanishing on the diagonal.**\n",
        "   $I_n(\\mathbf{p},\\mathbf{p}) = 0$ for all $\\mathbf{p}\\in\\Delta_n$.\n",
        "\n",
        "4. **Chain rule.**\n",
        "   \n",
        "    Given $n, k_1, \\ldots, k_n \\geq 1$ and $\\mathbf{w} \\in \\Delta_n$, $\\mathbf{p}^1 \\in \\Delta_{k_1}, \\ldots, \\mathbf{p}^n \\in \\Delta_{k_n}$, and writing $\\mathbf{p}^i = (p^i_1, \\ldots, p^i_{k_i})$, define the operation\n",
        "\n",
        "   $$\\mathbf{w} \\circ (\\mathbf{p}^1, \\ldots, \\mathbf{p}^n) = (w_1 p^1_1, \\ldots, w_1 p^1_{k_1}, \\ldots, w_n p^n_1, \\ldots, w_n p^n_{k_n}) \\in \\Delta_{k_1 + \\cdots + k_n}.$$\n",
        "\n",
        "   The **chain rule** is\n",
        "\n",
        "   $$I_{k_1 + ... + k_n}(\\mathbf{w} \\circ (\\mathbf{p}^1, \\ldots, \\mathbf{p}^n) , \\tilde{\\mathbf{w}} \\circ (\\tilde{\\mathbf{p}}^1, \\ldots, \\tilde{\\mathbf{p}}^n)) = I_n(\\mathbf{w} , \\tilde{\\mathbf{w}}) + \\sum_{i=1}^n w_i I_{k_i}(\\mathbf{p}^i , \\tilde{\\mathbf{p}}^i) \\quad (3)$$\n",
        "\n",
        "   whenever $(\\mathbf{w}, \\tilde{\\mathbf{w}}) \\in A_n$ and $(\\mathbf{p}^i, \\tilde{\\mathbf{p}}^i) \\in A_{k_i}$.\n",
        "\n",
        "#### Note:\n",
        "   This way of defining the chain rule relates to the way it was defined previously for $D_{KL}$:\n",
        "\n",
        "\n",
        "1. Draw an index $i\\in\\{1,\\dots,n\\}$ according to the “marginal” probability vector\n",
        "\n",
        "$$\n",
        "  w=(w_1,\\dots,w_n)\\,.\n",
        "$$\n",
        "\n",
        "2. Given that you drew $i$, draw the “inner” outcome $j$ from to the conditional distribution\n",
        "\n",
        "$$\n",
        "  p^i=(p^i_1,\\dots,p^i_{k_i})\\,.\n",
        "$$\n",
        "\n",
        "Then\n",
        "\n",
        "$$\n",
        "  w\\circ (p^1,\\dots,p^n)\n",
        "$$\n",
        "\n",
        "is precisely the joint distribution $P(i,j)$.  Similarly,\n",
        "$\\widetilde w\\circ(\\tilde p^1,\\dots,\\tilde p^n)$\n",
        "is another joint distribution $Q(i,j)$.  The chain rule\n",
        "\n",
        "$$\n",
        "  D_{KL}\\bigl(w\\circ p^1\\!,\\dots,p^n\\bigm\\|\\;\\widetilde w\\circ\\tilde p^1,\\dots,\\tilde p^n\\bigr)\n",
        "  \\;=\\;\n",
        "  D_{KL}(w\\|\\widetilde w)\\;+\\;\\sum_{i=1}^n w_i\\,D_{KL}\\bigl(p^i\\|\\tilde p^i\\bigr)\n",
        "$$\n",
        "\n",
        "now reads\n",
        "\n",
        "$$\n",
        "  D_{KL}\\bigl(P(i,j)\\,\\big\\|\\,Q(i,j)\\bigr)\n",
        "  \\;=\\;\n",
        "  D_{KL}\\bigl(P(i)\\,\\big\\|\\,Q(i)\\bigr)\n",
        "  \\;+\\;\\sum_{i=1}^n P(i)\\;D\\bigl(P(j\\mid i)\\,\\big\\|\\,Q(j\\mid i)\\bigr).\n",
        "$$\n",
        "\n",
        "But that sum is nothing but the expectation (under $P$) of the conditional KL–divergence:\n",
        "\n",
        "$$\n",
        "  \\sum_i P(i)\\;D_{KL}\\bigl(P(j\\mid i)\\,\\big\\|\\,Q(j\\mid i)\\bigr)\n",
        "  \\;=\\;\n",
        "  \\mathbb E_{P}\\!\\Bigl[D_{KL}\\bigl(P(j\\mid i)\\,\\big\\|\\,Q(j\\mid i)\\bigr)\\Bigr].\n",
        "$$\n",
        "\n",
        "Hence,\n",
        "\n",
        "$$\n",
        "  D_{KL}\\bigl(P(x,y)\\,\\big\\|\\,Q(x,y)\\bigr)\n",
        "  \\;=\\;\n",
        "  D_{KL}\\bigl(P(x)\\,\\big\\|\\,Q(x)\\bigr)\n",
        "  \\;+\\;\\mathbb E_{P}\\!\\bigl[D(P(y\\mid x)\\,\\|\\,Q(y\\mid x))\\bigr].\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "**The KL divergence is (up to a constant factor) the unique function satisfying these 4 properties. In other words, $I_n(- ,-) = c D_{KL}(-\\|-)$ for $c \\in \\mathbb{R}$.**\n",
        "\n",
        "## Proof:\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### Step 1. The “one‑bit” function\n",
        "\n",
        "Define\n",
        "\n",
        "$$\n",
        "L(\\alpha)\n",
        "=\n",
        "I_2\\!\\bigl((1,0),(\\alpha,1-\\alpha)\\bigr),\n",
        "\\quad\n",
        "\\alpha\\in(0,1].\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "### Step 2. Decomposition Lemma\n",
        "\n",
        "Let $(\\mathbf{p},\\mathbf{r})\\in A_n$ have exactly $k$ positive entries, in which $p_{k+1}=\\cdots=p_n=0$.  Set\n",
        "\n",
        "$$\n",
        "R = r_1+\\cdots+r_k,\n",
        "\\quad\n",
        "\\mathbf{p}'=(p_1,\\dots,p_k),\n",
        "\\quad\n",
        "\\mathbf{r}'=\\tfrac1R\\,(r_1,\\dots,r_k).\n",
        "$$\n",
        "\n",
        "Then\n",
        "\n",
        "$$I(\\mathbf{p}, \\mathbf{r}) = L(R) + I(\\mathbf{p}', \\mathbf{r}').$$\n",
        "\n",
        "**Proof:**\n",
        "\n",
        "- For $k = n$,\n",
        "\n",
        "   $$I(\\mathbf{p}, \\mathbf{r}) = 0 + I(\\mathbf{p}, \\mathbf{r}) = I_2((1,0), (1,0)) + I(\\mathbf{p}, \\mathbf{r}) = L(1) + I(\\mathbf{p}, \\mathbf{r}). $$\n",
        "\n",
        "-  For $k < n$,\n",
        "\n",
        "      Since $\\mathbf{p}$ is a distribution with $p_i = 0$ for all $i>k$, there is some $i \\leq k$ such that $p_i >0$, which implies $r_i >0$ and $R>0$.\n",
        "\n",
        "   Let $\\tilde{R} = 1-R$.\n",
        "   Let $\\mathbf{r}'' \\in \\Delta_{n-k}$ be the normalization of $(r_{k+1}, ..., r_{n})$ if $\\tilde{R}>0$ or choose $\\mathbf{r}''$ arbitrarily in $\\Delta_{n-k}$ otherwise (which is possible since $k<n$). Then\n",
        "\n",
        "   $$I(\\mathbf{p}, \\mathbf{q}) = I((1,0) \\circ (\\mathbf{p}', \\mathbf{r}''), (R, 1-R) \\circ (\\mathbf{r}', \\mathbf{r}''))$$\n",
        "\n",
        "   And applying the chain rule\n",
        "\n",
        "   $$I(\\mathbf{p}, \\mathbf{q}) = L(R) + I(\\mathbf{p}', \\mathbf{q}').$$\n",
        "\n",
        "### Step 3. Multiplicativity of $L$\n",
        "\n",
        "Consider\n",
        "\n",
        "$$\n",
        "x = I_3\\bigl((1,0,0),(\\alpha\\beta,\\alpha(1-\\beta),1-\\alpha)\\bigr).\n",
        "$$\n",
        "\n",
        "* Using the decompositon lemma, letting $k = 1$,\n",
        "\n",
        "  $x = L(\\alpha \\beta) + I_1((1),(1)) = L(\\alpha \\beta)\\quad$  (from vanishing property).\n",
        "* Using the decompositon lemma, letting $k = 2$,\n",
        "$$x  = L(\\alpha) + I_2((1,0),\\left(\\frac{\\alpha \\beta}{\\alpha}, \\frac{\\alpha (1-\\beta)}{\\alpha}\\right))v = L(\\alpha) + I_2((1,0),(\\beta,  (1-\\beta))$$\n",
        "$$= L(\\alpha) + L(\\beta).$$\n",
        "\n",
        "We then conclude $L(\\alpha \\beta) = L(\\alpha) + L(\\beta)$.\n",
        "\n",
        "\n",
        "### Step 4. Solving the functional equation\n",
        "\n",
        "Measurability plus $L(αβ)=L(α)+L(β)$ force\n",
        "\n",
        "$$\n",
        "L(\\alpha) = -\\,c\\,\\ln\\alpha\n",
        "$$\n",
        "\n",
        "for some constant $c$.\n",
        "\n",
        "### Step 5. Full‑support case\n",
        "\n",
        "Consider $(\\mathbf{p}, \\mathbf{q}) \\in A_n$ with $p_i>0$ for all $i = 1,...,n$. This implies $r_i>0$ for all $i$.\n",
        "\n",
        "Choose $\\alpha \\in (0, 1]$ such that $r_i - \\alpha p_i \\geq 0$ for all $i$. Now, let\n",
        "\n",
        "$x = I((p_1,...,p_n, \\underbrace{0,...,0}_n), (\\alpha p_1, ..., \\alpha p_n, r_1 - \\alpha p_1,...,r_n-\\alpha p_n))$.\n",
        "\n",
        "We will compute $x$ in two ways.\n",
        "   - By the decomposition lemma with $k = n$,\n",
        "      $$x = L(\\alpha) + I\\left(p, \\frac{1}{\\alpha}\\alpha p \\right) = L(\\alpha). \\quad \\text{(from vanishing property)}$$\n",
        "   - By the permutation invariance property\n",
        "      $$x = I((p_1, 0, p_2, 0,..., p_n, 0), (\\alpha p_1, r_1 - \\alpha p_1, \\alpha p_2, p_2-\\alpha r_2,...,\\alpha p_n, r_n - \\alpha p_n))$$\n",
        "      $$ \\quad= I(\\mathbf{p} \\circ ((1,0),...,(1,0)), \\mathbf{r} \\circ (\\left(\\alpha \\frac{p_1}{r_1}, 1-\\alpha\\frac{p_1}{r_1}\\right), ..., \\left(\\alpha \\frac{p_n}{r_n}, 1-\\alpha\\frac{p_n}{r_n}\\right)) )$$\n",
        "      $$=I(\\mathbf{p}, \\mathbf{r}) + \\sum_{i=1}^n p_i L\\left(\\alpha \\frac{p_i}{r_i}\\right) \\quad \\text{(from chain rule)}$$\n",
        "      $$=I(\\mathbf{p}, \\mathbf{r}) + L(\\alpha) + \\sum_{i=1}^n p_iL\\left(\\frac{p_i}{r_i}\\right) \\quad \\text{ (from multiplicative rule)}$$\n",
        "      \n",
        "Thus, from the we have that from the two expressions for $x$,\n",
        "\n",
        "$$I(\\mathbf{p}, \\mathbf{r}) + \\sum_{i=1}^n p_i L\\left(\\frac{p_i}{r_i}\\right) = 0$$\n",
        "$$\\downarrow$$\n",
        "$$I(\\mathbf{p}, \\mathbf{r}) =  c D_{KL}(\\mathbf{p}, \\mathbf{r}).$$\n",
        "\n",
        "\n",
        "### Step 6. General case\n",
        "\n",
        "For arbitrary $(\\mathbf{p},\\mathbf{r})$, permute to move zeros to the end, apply the Decomposition Lemma once to peel off the zero‑block (using vanishing again), then invoke the full‑support result on the remaining block.  This yields\n",
        "\n",
        "$$\n",
        "I(\\mathbf{p},\\mathbf{r})\n",
        "=\n",
        "c\\,D_{\\mathrm{KL}}(\\mathbf{p}\\|\\mathbf{r}),\n",
        "$$\n",
        "\n",
        "completing the uniqueness proof.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "k2USvVBsR_uo"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K1txlJKeSAN9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}